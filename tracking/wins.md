# Wins Tracking

**Update frequency:** Immediately when something works

---

## HOW TO USE

- Document wins with specifics (not vague "good progress")
- Include actual metrics
- Analyze WHY it worked
- Define how to repeat/scale

**Remember:** A win without analysis is just luck. Make it repeatable.

---

## Week 1 Wins

### Win #1: First Payment Sent - Broke the Ice

**Date:** January 13, 2026

**What we did:**
- Received first social job submission (Campaign 1: "Why Nubcat Is Underrated")
- Submission didn't follow guidelines (low-effort "Interesting read ðŸ‘€" instead of 50+ char commentary)
- Participant had only 40 followers (below our new 500 minimum)
- BUT participant helped find bugs in submission flow
- We paid them anyway (509 $NUB)
- Tweeted about the payment from both @galborta and @useOrggly

**Result:**
- First proof that payment system works end-to-end
- Social proof created (community can see someone actually got paid)
- Platform bugs identified and reported
- Went from 0 submissions to 3 in one day (1 social job + 2 banner designs)
- Total paid: 509 $NUB

**Why it worked:**
- Flexibility matters more than perfect guidelines early on
- Rewarding helpful behavior (bug finding) builds goodwill
- First payment breaks psychological barrier for others
- Public celebration creates social proof
- Showing we follow through is more valuable than enforcing quality at day 1

**Key insight:**
The first payment is more about proving the system works than getting perfect content. Once people see someone actually got paid, they'll feel safer participating. Quality can be enforced later once you have volume.

**How to repeat:**
1. When receiving imperfect early submissions, look for ANY value-add beyond content
2. Pay them if they contributed something (bug reports, feedback, community intro)
3. Celebrate payment publicly to create social proof
4. Use founder voice to acknowledge imperfection but emphasize follow-through
5. Set clearer guidelines for future submissions based on what you learned

**How to scale:**
- Can't pay everyone who doesn't follow guidelines forever
- But in first week, prioritize proof of payment over perfect quality
- After 5-10 payments, can start enforcing standards
- The social proof compounds: each payment makes next one easier

**Related learnings:**
- Need to add Twitter handle request to all submission forms
- 500 follower minimum might kill early participation (monitor)
- Guidelines need to be clearer or we need to accept minimum viable effort
- Banner contest (higher effort, bigger prize) got faster traction than social jobs

---

### Win #2: Banner Contest Getting Early Traction

**Date:** January 13, 2026

**What we did:**
- Launched Twitter banner design contest featuring Nubcat
- 10,000 $NUB prize for winner
- All participants get paid for effort
- 6 day deadline

**Result:**
- 2 submissions in first 24 hours
- Both designers submitted without us doing any outreach
- Shows higher-effort creative work is attractive with bigger prizes
- Still 5d 21h remaining to get more submissions

**Why it worked:**
- Creative work is more appealing than repetitive social posts
- 10,000 $NUB prize is significant motivation (vs $8-90 for social jobs)
- Clear deliverable (banner design) vs vague "thoughtful commentary"
- Novelty: first contest vs ongoing social job campaigns
- Designers get to showcase their work publicly

**Key insight:**
Higher effort + higher reward + creative freedom = better early participation than low-effort repetitive tasks. People want to create, not just spam.

**How to repeat:**
1. Create contests with specific creative deliverables
2. Make prizes 10x+ the normal per-task rate
3. Guarantee payment for all participants (not just winner)
4. Give credit publicly to all submissions
5. Let community vote on winner (engagement + fairness)

**How to scale:**
- Can't run 10K prize contests constantly (budget)
- But could do monthly featured contests
- Alternate: big creative contests + ongoing social jobs
- Use contests to attract designers/creators, social jobs for reach

**Related learnings:**
- Missing designer Twitter handles (need to add to submission flow)
- Design quality is mixed but shows people are trying
- Consider creating design tier system (logo, banner, graphics) with different prizes
- Community voting could boost engagement

---

### Win #3: Campaign Goes Viral - 845 Participants, 675 Retweets

**Date:** January 14, 2026

**What we did:**
- Nubcat campaign article went viral on Twitter
- Quote tweet campaign gained massive organic traction
- Orggly x Nubcat social campaigns collected submissions

**Result:**
- 675 retweets on the campaign article
- 845 total participants submitted to the social campaign
- Massive jump from 3 submissions (day 1) to 845 participants (day 2-3)
- Budget: ~10,000 $NUB available for payouts
- Currently reviewing submissions for guideline compliance before payment

**Why it worked:**
- Article resonated with Nubcat community
- Quote tweet format encouraged participation (low friction)
- Social proof kicked in once participation started
- Nubcat community is highly engaged and active
- Payment promise is credible after first payment proof

**Key insight:**
Going from 3 to 845 participants overnight proves the model works at scale. The bottleneck wasn't interest or participation, it was trust. Once you prove you pay, communities will engage. Now the challenge shifts from "getting submissions" to "managing quality and review at scale."

**How to repeat:**
1. Build initial trust with small provable payments (first 3-5)
2. Create low-friction participation (quote tweet vs essay)
3. Partner with engaged communities (not just any token)
4. Let article/announcement go viral organically before pushing
5. Have review infrastructure ready BEFORE campaign goes viral

**How to scale:**
- Need systematic review process (can't manually review 845 submissions)
- Create clear quality tiers with corresponding payouts
- Build community moderation (let community flag violations)
- Automate payment distribution once review is done
- Template this playbook for next token community partnership

**Review approach planned:**
- Tier 1 (Excellent): ~15% of submissions, highest payout
- Tier 2 (Good): ~35% of submissions, medium payout  
- Tier 3 (Basic but valid): ~30% of submissions, base payout
- Rejected: ~20% didn't follow guidelines, no payment
- Total budget: ~10,000 $NUB distributed across approved submissions

**Related learnings:**
- Viral campaigns create review bottleneck (need process before launch)
- Quality distribution in mass participation is wide (expect 20% to ignore guidelines)
- Community trust compounds exponentially once proven
- Next campaign needs automated quality checks or community moderation
- This validates the Orggly model at scale

---

## Win Template (Copy This for New Wins)

### Win #[X]: [Name]

**Date:** [When it happened]

**What we did:**
- [Specific action taken]

**Result:**
- [Concrete outcome with metrics]
- [Numbers: impressions, submissions, responses, etc.]

**Why it worked:**
- [Analysis of success factors]
- [What was different from previous attempts]

**Key insight:**
[The one thing to remember from this]

**How to repeat:**
- [Specific steps to replicate]
- [Conditions needed for this to work again]

**How to scale:**
- [Ways to do more of this]
- [Potential to expand approach]

**Related learnings:**
- [Connections to other wins/fails]
- [Broader patterns emerging]

---

**Last updated:** January 14, 2026  
**Next win:** TBD (currently reviewing 845 submissions from viral campaign)
